{
 "metadata": {
  "language": "Julia",
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Astro 585 Spring 2014<br>\n",
      "Homework 6:  Parallel Computing:  Multi-Core Workstations"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Q1.  First, we'll parallelize some simple code from a previous exercise.  I'll walk you though the syntax in Julia and highlight some potential mistakes."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, check how many processors your computer has.  On linux, you can do this by running /cat/cpuinfo from the command line and seeing how many processors are listed.\n",
      "If your machine only has one, then ssh to another computer with Julia installed for the parallel parts.  \n",
      "Next, check how many processor Julia is currently using."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nprocs()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "1"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When using the REPL interface, you can tell Julia to use multiple cores on a single workstation by starting it like \"julia -p 4\".\n",
      "When using IJulia, it's easier to tell it to add processors from within the notebook with the addprocs(N) command.\n",
      "Using addprocs(N) to tell Julia to use as many processors as your workstation has.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "addprocs(4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "4-element Array{Any,1}:\n",
        " 2\n",
        " 3\n",
        " 4\n",
        " 5"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, check how many processor and how many \"workers\" are active."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "println(\"nprocs()= \",nprocs())\n",
      "println(\"nworkers()= \",nworkers())\n",
      "println(\"myid()= \",myid())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "nprocs()= 5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "nworkers()= 4\n",
        "myid()= 1\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "####1a.  What's the differences between nprocs() and nworkers()?\n",
      "\n",
      "Issuing help(nprocs) we get:\n",
      "    Loading help data...\n",
      "    Base.nprocs()\n",
      "    \n",
      "       Get the number of available processors.\n",
      "\n",
      "Issuing help(nworkers) we get:\n",
      "    Base.nworkers()\n",
      "\n",
      "       Get the number of available worker processors. This is one less\n",
      "       than nprocs(). Equal to nprocs() if nprocs() == 1.\n",
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can instruct Julia to start a calculation on another node using @spawn or @spawnat.  \n",
      "Since the whole point is you want multiple processors working at once, you don't want to have ot wait until that function finished.\n",
      "Therefore, these macros return a RemoteRef data type, rather than the return value.  You can retreive the returned value using fetch."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ref = @spawn 1+1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "RemoteRef(5,1,10)"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fetch(ref)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "2"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define our beloved normal pdf function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "normal_pdf(x) = exp(-0.5*x.*x)./sqrt(2.*pi)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "normal_pdf (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's write a loop-based integrate function like from the previous lab."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Calculate \\int_a^b dx func(x) using n function evaluations\n",
      "# Approximates integral as uniformly spaced rectangles\n",
      "# Avoids evaluating func at a or b, in case of singularities\n",
      "function int_normal_pdf(a::Real, b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  integral = 0.\n",
      "  for i in 1:n\n",
      "    x = a+i*(b-a)/(n+1)\n",
      "    integral += normal_pdf(x)\n",
      "  end\n",
      "  integral *= (b-a)/n;\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "int_normal_pdf (generic function with 2 methods)"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's write a function to perform a few tests that our function is accurate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using Base.Test\n",
      "function test_int_normal_pdf(func::Function; n::Integer = 1000000, eps::Real = 1.0e-6)\n",
      "  limits = 1:5\n",
      "  for limit in limits\n",
      "    @test_approx_eq_eps func(-limit,limit) erf(limit/sqrt(2.0)) eps\n",
      "  end\n",
      "end\n",
      "test_int_normal_pdf(int_normal_pdf)\n",
      "@time  int_normal_pdf(-1.0,1.0,1000000)\n",
      "@time  int_normal_pdf(-1.0,1.0,1000000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 0."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "056297811 seconds (143572 bytes allocated)\n",
        "elapsed time: 0.053352432 seconds (64 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "0.6826896908849539"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, let's parallelize that loop using the @parallel macro and test the function for accuracy."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function int_normal_pdf(a::Real, b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  integral = 0.\n",
      "  @parallel for i in 1:n\n",
      "    x = a+i*(b-a)/(n+1)\n",
      "    integral += normal_pdf(x)\n",
      "  end\n",
      "  integral *= (b-a)/n;\n",
      "end\n",
      "\n",
      "test_int_normal_pdf(int_normal_pdf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "LoadError",
       "evalue": "assertion failed: |:(func(-(limit),limit)) - :(erf(/(limit,sqrt(2.0))))| <= 1.0e-6\n  :(func(-(limit),limit)) = 0.0\n  :(erf(/(limit,sqrt(2.0)))) = 0.6826894921370859\n  difference = 0.6826894921370859 > 1.0e-6\nwhile loading In[5], in expression starting on line 11",
       "output_type": "pyerr",
       "traceback": [
        "assertion failed: |:(func(-(limit),limit)) - :(erf(/(limit,sqrt(2.0))))| <= 1.0e-6\n  :(func(-(limit),limit)) = 0.0\n  :(erf(/(limit,sqrt(2.0)))) = 0.6826894921370859\n  difference = 0.6826894921370859 > 1.0e-6\nwhile loading In[5], in expression starting on line 11",
        " in error at error.jl:22",
        " in test_approx_eq at test.jl:68",
        " in test_int_normal_pdf at In[4]:5"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "####1b.  Notice that we get messages like normal_pdf not defined.  Why is that?\n",
      "I wasn't exactly sure at first, but it seems that we are only defining the functions on one processor - now we are using 4 processors; on three of which the functions are undefined.\n",
      "\n",
      "---\n",
      "\n",
      "We've defined functions on only the first processor.  We need to make sure they're also definied on any other processors that we want to use the functions.  The easiest way to do that is with the @everywhere macro.  You can either stick it in front of each function (in your notebook) or save the functions to a file and load them with @everywhere include(\"file.jl\").  \n",
      "Let's redefine the above functions, but now forcing them to be declared on each processor."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@everywhere normal_pdf(x) = exp(-0.5*x.*x)./sqrt(2.*pi)\n",
      "@everywhere using Base.Test\n",
      "\n",
      "@everywhere function test_int_normal_pdf(func::Function; n::Integer = 1000000, eps::Real = 1.0e-6)\n",
      "  limits = 1:5\n",
      "  for limit in limits\n",
      "    @test_approx_eq_eps func(-limit,limit) erf(limit/sqrt(2.0)) eps\n",
      "  end\n",
      "end\n",
      "\n",
      "@everywhere function int_normal_pdf(a::Real, b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  integral = 0.\n",
      "  @parallel for i in 1:n\n",
      "    x = a+i*(b-a)/(n+1)\n",
      "    integral += normal_pdf(x)\n",
      "  end\n",
      "  integral *= (b-a)/n\n",
      "end\n",
      "\n",
      "test_int_normal_pdf(int_normal_pdf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "LoadError",
       "evalue": "assertion failed: |:(func(-(limit),limit)) - :(erf(/(limit,sqrt(2.0))))| <= 1.0e-6\n  :(func(-(limit),limit)) = 0.0\n  :(erf(/(limit,sqrt(2.0)))) = 0.6826894921370859\n  difference = 0.6826894921370859 > 1.0e-6\nwhile loading In[24], in expression starting on line 21",
       "output_type": "pyerr",
       "traceback": [
        "assertion failed: |:(func(-(limit),limit)) - :(erf(/(limit,sqrt(2.0))))| <= 1.0e-6\n  :(func(-(limit),limit)) = 0.0\n  :(erf(/(limit,sqrt(2.0)))) = 0.6826894921370859\n  difference = 0.6826894921370859 > 1.0e-6\nwhile loading In[24], in expression starting on line 21",
        " in error at error.jl:22",
        " in test_approx_eq at test.jl:68",
        " in test_int_normal_pdf at In[24]:7"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "####1c.  Now, we've eliminated some of the error messages, but our test still fails.  And it can fail badly.  Why is that?\n",
      "\n",
      "Our assertion failed, the calculated integral is not correct. We have a race condition: we are not synchronizing the additions for the variable `integral` - the different processess can be reading and writing at the same time, which results in a wrong result.\n",
      "\n",
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This type of operation is so common, that Julia provides a special syntax that makes this kind of loop easy:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@everywhere function int_normal_pdf(a::Real, b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  integral = @parallel (+) for i in 1:n\n",
      "    x = a+i*(b-a)/(n+1)\n",
      "    normal_pdf(x)\n",
      "  end\n",
      "  integral *= (b-a)/n;\n",
      "end\n",
      "\n",
      "test_int_normal_pdf(int_normal_pdf)\n",
      "@time  int_normal_pdf(-1.0,1.0,1000000)\n",
      "@time  int_normal_pdf(-1.0,1.0,1000000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 0."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "039388654 seconds (249808 bytes allocated)\n",
        "elapsed time: 0.028404614 seconds (2432 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "0.6826896908849539"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here Julia is taking the last line of the for loop as the value to be \"reduced\" by the \"+\" operator and the result is stored in integral.  Note that the loop is no longer executed in order, since different processors are executing different parts of the loop."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, let's try performing the same calculation using parallel map function (pmap)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function int_normal_pdf(a::Real,b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  dx = (b-a)/n\n",
      "  x = (a+0.5*dx):dx:(b-0.5*dx)\n",
      "  integral = sum(pmap(normal_pdf,x)) * (b-a)/n \n",
      "end\n",
      "#test_int_normal_pdf(int_normal_pdf)  # Commented out for speed's sake\n",
      "@time  int_normal_pdf(-1.0,1.0,10000)\n",
      "@time  int_normal_pdf(-1.0,1.0,10000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 0."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "207935761 seconds (16786168 bytes allocated)\n",
        "elapsed time: 0.04429237 seconds (12267064 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "0.682689492943655"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Yikes, that's crazy slow.  You may even want to restart the kernel.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we'll make use of distributed arrays to demonstrate how to handle more complex parallelization tasks."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function int_normal_pdf(a::Real, b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  x = distribute([ a+i*(b-a)/(n+1) for i in 1:n ])\n",
      "  integral = sum(map(normal_pdf,x)) * (b-a)/n \n",
      "end \n",
      "#test_int_normal_pdf(int_normal_pdf)  # Commented out for speed's sake\n",
      "@time  int_normal_pdf(-1.0,1.0,10000)\n",
      "@time  int_normal_pdf(-1.0,1.0,10000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 0."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "538706482 seconds (30039040 bytes allocated)\n",
        "elapsed time: 0.022335089 seconds (8041000 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "0.682709365328419"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function int_normal_pdf(a::Real, b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  x = distribute([ a+i*(b-a)/(n+1) for i in 1:n ])\n",
      "  integral = sum(pmap(normal_pdf,x)) * (b-a)/n \n",
      "end\n",
      "#test_int_normal_pdf(int_normal_pdf)  # Commented out for speed's sake\n",
      "@time  int_normal_pdf(-1.0,1.0,10000)\n",
      "@time  int_normal_pdf(-1.0,1.0,10000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 0."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "169201822 seconds (21812016 bytes allocated)\n",
        "elapsed time: 0.074712713 seconds (19752592 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "0.682709365328419"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "While we succeeded in using distributed array, the performance wasn't very good.  \n",
      "Next, we'll implement a more efficient parallelization using distribute arrays.  \n",
      "For this, you'll need to look up several functions in line 3 below and consider them piece by piece.  \n",
      "First, create a distributed array with dzeros, dones, drand or drandn.  \n",
      "Then, look at which processors are storing data for that array with procs().\n",
      "Then, check how much of the array is stored on the processor running your notebook using localpart() or myindexes()\n",
      "Then, use @spawnat and localpart() to have a processor operate only on the portion of the distributed array that it has in its own memory.\n",
      "Then use fetch with map to retreive the results from each processor working on it's own portion of the distributed array.\n",
      "Finally, use reduce to combine all these elements.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function int_normal_pdf(a::Real, b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  x = distribute([ a+i*(b-a)/(n+1) for i in 1:n ])\n",
      "  integral = (b-a)/n * reduce(+,map(fetch,{ (@spawnat p sum(normal_pdf(localpart(x)))) for p in procs(x) }))\n",
      "end\n",
      "test_int_normal_pdf(int_normal_pdf)\n",
      "@time  int_normal_pdf(-1.0,1.0,1000000)\n",
      "@time  int_normal_pdf(-1.0,1.0,1000000)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 0."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "067938506 seconds (48290560 bytes allocated)\n",
        "elapsed time: 0.040623776 seconds (48011112 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "0.6826896908849678"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see, @parallel is better suited for small loops that execute quickly.\n",
      "Map and pmap are more useful for distributing more time consuming functions.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Question 2\n",
      "\n",
      "Q2.  In this exercise, you'll parallelize a more time consuming simulation task.  We'll consider a population of stars, each of which has a  probability $\\eta$ of having one planet.  Then we'll assume a that the planets' orbital periods are drawn from a truncated inverse gamma distribution.  An inverse gamma distribution takes two model parameters, one shape parameter that is like a power-law index for large orbital periods and one scale factor that determines below what period planets will become much less common.  We'll truncate the period distribution, so that no planets orbit inside a star or have a period greater than 4/3 of a year (based on Kepler's mission lifetime).  Each planet has a probability of transiting it's star approximated by $R_*/a$, where $R_*$ is the radius of the star and a is the semi-major axis of the orbit (related to orbital period via Kepler's third law).  (For simplicity, we'll make many assumptions like all stars will be one solar mass and one solar radius, no planet will be too small to be detected above the noise, each star can have only zero or one planets, planets will be on circular orbits, etc. )   We will generate one set of \"observations\" using a particular set of parameter values.  Then we will explore the three-dimensional parameter space ($\\eta$, shape, scale), pretending that we don't know the true values.   For each set of model parameters that we consider, we'll generate one (or more) simulated data sets and comapre those to the \"observations\" via several summary statistics (e.g., number of transiting planets, mean period of transiting planets, standard deviation of transiting planets, etc.) and record a \"distance\" between the summary statistics of the observations and the summary statistics for the simulated data.  You can then plot various projections of this 3-d function to gain intuition for what combinations of $\\eta$, shape and scale are plaussible matches to the data.  \n",
      "\n",
      "##:::NOTE: RESTART THE KERNEL HERE:::"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#2a.\n",
      "First, read through and load the two files that contain a starter program.\n",
      "Then, perform a set of simulations using parameters similar to those below.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@everywhere include(\"HW6_Q2_planet_populations_once.jl\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tFrom worker 3:\tLoading help data...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tFrom worker 5:\tLoading help data...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tFrom worker 4:\tLoading help data...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tFrom worker 2:\tLoading help data...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading help data...\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Pkg.update()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Updating METADATA..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Updating cache of JSON..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Updating cache of ZMQ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Updating cache of HDF5..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Computing changes..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Upgrading Distributions: v0.4.0 => v0.4.2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Upgrading HDF5: v0.2.17 => v0.2.20"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Upgrading JSON: v0.3.3 => v0.3.5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Upgrading NumericExtensions: v0.5.4 => v0.5.6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Upgrading PDMats: v0.1.0 => v0.1.1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Upgrading StatsBase: v0.3.7 => v0.3.9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Upgrading ZMQ: v0.1.8 => v0.1.9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Building HDF5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Building ZMQ"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@everywhere using Distributions; #NOTE: You have to have @everywhere here!!\n",
      "using PyPlot;\n",
      "@everywhere const days_in_year = 365.2425; #NOTE: You have to have @everywhere here!!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading help data...\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@everywhere include(\"HW6_Q2_planet_populations.jl\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "min_eta = 0.0\n",
      "max_eta = 1.0\n",
      "min_shape = 0.0001\n",
      "max_shape = 1.0\n",
      "min_log_scale = log10(0.3)\n",
      "max_log_scale = log10(3.0)  \n",
      "num_eta = 4\n",
      "num_shape = 4\n",
      "num_scale = 4\n",
      "num_evals = 1\n",
      "etas = linspace(min_eta,max_eta,num_eta)\n",
      "scales = 10.0.^linspace(min_log_scale,max_log_scale,num_scale)\n",
      "shapes = linspace(min_shape,max_shape,num_shape)\n",
      "num_stars = 1600 # Note - I changed this - was 16000 - for speedups\n",
      "eta = 0.2\n",
      "shape = 0.1\n",
      "scale = 1.0;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Serial - note `num_stars`=1600"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "srand(42)\n",
      "@time result = eval_model_on_grid_loops(etas,shapes,scales,num_stars; num_evals = num_evals, true_eta = eta, true_shape = shape, true_scale = scale);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".764715133 seconds (25160588 bytes allocated)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "4x4x4 Array{Float64,3}:\n",
        "[:, :, 1] =\n",
        " 1.15202   1.15202   1.15202   1.15202\n",
        " 2.10526   4.78947   7.52632  11.7895 \n",
        " 4.78947  11.8947   18.6842   24.6316 \n",
        " 7.26316  16.8947   27.9474   37.5263 \n",
        "\n",
        "[:, :, 2] =\n",
        " 1.15202  1.15202   1.15202   1.15202\n",
        " 1.36842  1.94737   4.84211   6.73684\n",
        " 2.42105  6.15789  11.3684   14.3158 \n",
        " 4.52632  9.36842  16.6316   23.0    \n",
        "\n",
        "[:, :, 3] =\n",
        " 1.15202   1.15202  1.15202   1.15202\n",
        " 0.677728  1.42105  2.84211   3.21053\n",
        " 1.36842   4.21053  6.31579   9.21053\n",
        " 2.42105   4.68421  9.31579  14.5263 \n",
        "\n",
        "[:, :, 4] =\n",
        " 1.15202  1.15202  1.15202  1.15202\n",
        " 1.11388  1.03812  1.29212  1.94737\n",
        " 1.43902  1.63158  3.89474  4.63158\n",
        " 1.34574  4.57895  5.94737  7.68421"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that for speed's sake, I've limited the number of function evaluations to only 4 in each of the three model parameters.  \n",
      "Additionally, I've reduced the number of stars to only 16000 (NOTE: I put it to 8000)  Kepler observed ~160,000 stars at a time.  \n",
      "\n",
      "You might like to plot the results, using a command such as "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using PyPlot\n",
      "PyPlot.contour(log10(scales),shapes,[minimum(result[:,j,k]) for j in 1:num_scale, k in 1:num_shape])\n",
      "plot(log10([scale]),[shape],\"ro\")  # Put dot where true values of parameters are\n",
      "xlabel(L\"$\\log_{10}(\\mathrm{scale})$\");  ylabel(\"shape\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "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",
       "text": [
        "Figure(PyObject <matplotlib.figure.Figure object at 0x7ffe7ef24210>)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Q2b\n",
      "\n",
      "2b.  Parallelize at least one of the for loops to speed up the calculations performed by eval_model_on_grid_loops.  The easiest way will be to parallelize the inner-most loop (that's embedded inside evaluate_mode).  Test that your code gives similar results for at least a few sets of parameter values. (To save time, you don't need to test every point on the grid).  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Parallel:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Include the parallel versions:\n",
      "@everywhere include(\"HW6_Q2_planet_populations_par.jl\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Still only using one processor:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "println(\"nprocs()= \",nprocs())\n",
      "println(\"nworkers()= \",nworkers())\n",
      "println(\"myid()= \",myid())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "nprocs()= 1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "nworkers()= 1\n",
        "myid()= 1\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#PARALLEL\n",
      "srand(42)\n",
      "@time result_par = eval_model_on_grid_loops_par(etas,shapes,scales,num_stars; num_evals = num_evals, true_eta = eta, true_shape = shape, true_scale = scale);\n",
      "#PyPlot.contour(log10(scales),shapes,[minimum(result_par[:,j,k]) for j in 1:num_scale, k in 1:num_shape])\n",
      "#plot(log10([scale]),[shape],\"ro\")  # Put dot where true values of parameters are\n",
      "#xlabel(L\"$\\log_{10}(\\mathrm{scale})$\");  ylabel(\"shape\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".765258995 seconds (24644532 bytes allocated)\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result_par"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "4x4x4 Array{Float64,3}:\n",
        "[:, :, 1] =\n",
        " 1.15202   1.15202   1.15202   1.15202\n",
        " 2.10526   4.78947   7.52632  11.7895 \n",
        " 4.78947  11.8947   18.6842   24.6316 \n",
        " 7.26316  16.8947   27.9474   37.5263 \n",
        "\n",
        "[:, :, 2] =\n",
        " 1.15202  1.15202   1.15202   1.15202\n",
        " 1.36842  1.94737   4.84211   6.73684\n",
        " 2.42105  6.15789  11.3684   14.3158 \n",
        " 4.52632  9.36842  16.6316   23.0    \n",
        "\n",
        "[:, :, 3] =\n",
        " 1.15202   1.15202  1.15202   1.15202\n",
        " 0.677728  1.42105  2.84211   3.21053\n",
        " 1.36842   4.21053  6.31579   9.21053\n",
        " 2.42105   4.68421  9.31579  14.5263 \n",
        "\n",
        "[:, :, 4] =\n",
        " 1.15202  1.15202  1.15202  1.15202\n",
        " 1.11388  1.03812  1.29212  1.94737\n",
        " 1.43902  1.63158  3.89474  4.63158\n",
        " 1.34574  4.57895  5.94737  7.68421"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Lets check if they are the same"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using Base.Test\n",
      "@test_approx_eq result_par result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "No errors - so they are the same!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Q2c\n",
      "2c.  Compare the performance of your parallel code to the serial code while varrying the number of processors (e.g., 1, 2, 4, 8).\n",
      "For your benchmarking, make sure you use a computer that has at least 8 cores.  How does the wall clock time scale with the number of processors?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###2 processors:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Lets add one processor:\n",
      "addprocs(1)\n",
      "println(\"nprocs()= \",nprocs())\n",
      "println(\"nworkers()= \",nworkers())\n",
      "println(\"myid()= \",myid())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "nprocs()= 2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "nworkers()= 1\n",
        "myid()= 1\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We need to include this again - _everywhere_"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@everywhere using Distributions;\n",
      "using PyPlot;\n",
      "@everywhere const days_in_year = 365.2425;\n",
      "#Include the parallel versions:\n",
      "@everywhere include(\"HW6_Q2_planet_populations_par.jl\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Serial\n",
      "#srand(42)\n",
      "#@time result = eval_model_on_grid_loops(etas,shapes,scales,num_stars; num_evals = num_evals, true_eta = eta, true_shape = shape, true_scale = scale);\n",
      "\n",
      "#PARALLEL\n",
      "srand(42)\n",
      "@time result_par2 = eval_model_on_grid_loops_par(etas,shapes,scales,num_stars; num_evals = num_evals, true_eta = eta, true_shape = shape, true_scale = scale);\n",
      "#Lets test if serial, and parallel are the same\n",
      "#@test_approx_eq result_par2 result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".59798888 seconds (30608780 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "4x4x4 Array{Float64,3}:\n",
        "[:, :, 1] =\n",
        " 1.15202   1.15202   1.15202   1.15202\n",
        " 2.10526   4.31579   7.57895  11.6842 \n",
        " 4.52632  11.3684   18.9474   25.1579 \n",
        " 7.84211  17.7895   27.6316   38.6842 \n",
        "\n",
        "[:, :, 2] =\n",
        " 1.15202    1.15202   1.15202   1.15202\n",
        " 0.578947   2.78947   5.05263   6.89474\n",
        " 3.05263    6.52632  11.7368   13.8947 \n",
        " 4.73684   11.2632   16.3684   22.4737 \n",
        "\n",
        "[:, :, 3] =\n",
        " 1.15202   1.15202  1.15202   1.15202\n",
        " 0.550039  1.63158  2.84211   3.42105\n",
        " 1.78947   3.78947  5.84211   9.36842\n",
        " 2.94737   6.15789  9.15789  12.7895 \n",
        "\n",
        "[:, :, 4] =\n",
        " 1.15202  1.15202   1.15202  1.15202\n",
        " 1.20127  0.736842  1.57895  2.0    \n",
        " 1.79303  1.94737   3.78947  4.78947\n",
        " 2.21053  3.52632   5.52632  8.52632"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###3 processors:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Lets add one processor:\n",
      "addprocs(1)\n",
      "println(\"nprocs()= \",nprocs())\n",
      "println(\"nworkers()= \",nworkers())\n",
      "println(\"myid()= \",myid())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "nprocs()= 3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "nworkers()= 2\n",
        "myid()= 1\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@everywhere using Distributions;\n",
      "using PyPlot;\n",
      "@everywhere const days_in_year = 365.2425;\n",
      "#Include the parallel versions:\n",
      "@everywhere include(\"HW6_Q2_planet_populations_par.jl\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#PARALLEL\n",
      "srand(42)\n",
      "@time result_par3 = eval_model_on_grid_loops_par(etas,shapes,scales,num_stars; num_evals = num_evals, true_eta = eta, true_shape = shape, true_scale = scale);\n",
      "#@test_approx_eq result_par2 result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".067945796 seconds (11437680 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "4x4x4 Array{Float64,3}:\n",
        "[:, :, 1] =\n",
        " 1.15202   1.15202   1.15202   1.15202\n",
        " 1.68421   5.21053   9.10526  11.5789 \n",
        " 4.36842  11.6316   17.7368   24.2105 \n",
        " 7.31579  17.0526   26.8421   39.0526 \n",
        "\n",
        "[:, :, 2] =\n",
        " 1.15202    1.15202   1.15202   1.15202\n",
        " 0.684211   3.63158   5.26316   7.21053\n",
        " 2.57895    6.89474  12.1053   16.1579 \n",
        " 5.05263   10.3684   18.4211   22.7368 \n",
        "\n",
        "[:, :, 3] =\n",
        " 1.15202   1.15202    1.15202   1.15202\n",
        " 0.377497  0.894737   2.78947   3.94737\n",
        " 1.31579   3.73684    6.84211   8.63158\n",
        " 3.68421   6.84211   10.4211   13.6842 \n",
        "\n",
        "[:, :, 4] =\n",
        " 1.15202  1.15202  1.15202  1.15202\n",
        " 1.5136   1.7323   1.36842  2.0    \n",
        " 1.29274  1.68421  4.0      4.36842\n",
        " 1.52632  3.31579  5.47368  8.42105"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###4 processors:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Lets add one processor:\n",
      "addprocs(1)\n",
      "println(\"nprocs()= \",nprocs())\n",
      "println(\"nworkers()= \",nworkers())\n",
      "println(\"myid()= \",myid())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "nprocs()= 4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "nworkers()= 3\n",
        "myid()= 1\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@everywhere using Distributions;\n",
      "using PyPlot;\n",
      "@everywhere const days_in_year = 365.2425;\n",
      "#Include the parallel versions:\n",
      "@everywhere include(\"HW6_Q2_planet_populations_par.jl\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#PARALLEL\n",
      "srand(42)\n",
      "@time result_par3 = eval_model_on_grid_loops_par(etas,shapes,scales,num_stars; num_evals = num_evals, true_eta = eta, true_shape = shape, true_scale = scale);\n",
      "#@test_approx_eq result_par2 result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".016327457 seconds (11395848 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "4x4x4 Array{Float64,3}:\n",
        "[:, :, 1] =\n",
        " 1.15202   1.15202   1.15202   1.15202\n",
        " 1.21053   5.31579   8.26316  11.3684 \n",
        " 5.0      10.3684   18.8947   24.8421 \n",
        " 8.10526  18.1053   29.4737   38.1579 \n",
        "\n",
        "[:, :, 2] =\n",
        " 1.15202   1.15202   1.15202   1.15202\n",
        " 0.842105  2.31579   4.89474   7.31579\n",
        " 3.0       5.68421  10.0526   15.4211 \n",
        " 5.26316   9.15789  16.3684   22.3684 \n",
        "\n",
        "[:, :, 3] =\n",
        " 1.15202   1.15202  1.15202   1.15202\n",
        " 0.838662  1.36842  2.42105   4.05263\n",
        " 1.84211   3.26316  5.94737   8.73684\n",
        " 2.73684   6.68421  9.36842  15.0526 \n",
        "\n",
        "[:, :, 4] =\n",
        " 1.15202   1.15202   1.15202  1.15202\n",
        " 1.53901   0.982938  1.31579  1.63158\n",
        " 0.905969  1.73684   3.31579  4.15789\n",
        " 2.36842   3.63158   4.84211  7.78947"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##2d\n",
      "2d.  Modify part of the code, so as to replace the for loops in eval_model_on_grid_map with a call to the map function.  \n",
      "First, test this using a single processor.  Once that works, switch map to pmap and retest.\n",
      "\n",
      "##NOTE: RESTART KERNEL HERE:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Using map - and only one processor:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Lets add one processor:\n",
      "#addprocs(1)\n",
      "println(\"nprocs()= \",nprocs())\n",
      "println(\"nworkers()= \",nworkers())\n",
      "println(\"myid()= \",myid())\n",
      "min_eta = 0.0\n",
      "max_eta = 1.0\n",
      "min_shape = 0.0001\n",
      "max_shape = 1.0\n",
      "min_log_scale = log10(0.3)\n",
      "max_log_scale = log10(3.0)  \n",
      "num_eta = 4\n",
      "num_shape = 4\n",
      "num_scale = 4\n",
      "num_evals = 1\n",
      "etas = linspace(min_eta,max_eta,num_eta)\n",
      "scales = 10.0.^linspace(min_log_scale,max_log_scale,num_scale)\n",
      "shapes = linspace(min_shape,max_shape,num_shape)\n",
      "num_stars = 1600 # Note - I changed this - was 16000 - for speedups\n",
      "eta = 0.2\n",
      "shape = 0.1\n",
      "scale = 1.0;\n",
      "@everywhere using Distributions;\n",
      "using PyPlot;\n",
      "@everywhere const days_in_year = 365.2425;\n",
      "#Include the parallel versions:\n",
      "@everywhere include(\"HW6_Q2_planet_populations_par.jl\")\n",
      "#PARALLEL\n",
      "srand(42)\n",
      "@time result_map = eval_model_on_grid_map(etas,shapes,scales,num_stars; num_evals = num_evals, true_eta = eta, true_shape = shape, true_scale = scale);\n",
      "#@test_approx_eq result_par2 result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "nprocs()= 1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "nworkers()= 1\n",
        "myid()= 1\n",
        "elapsed time: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3.751372662 seconds (24185060 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "4x4x4 Array{Float64,3}:\n",
        "[:, :, 1] =\n",
        " 1.15202   1.15202   1.15202   1.15202\n",
        " 2.10526   4.78947   7.52632  11.7895 \n",
        " 4.78947  11.8947   18.6842   24.6316 \n",
        " 7.26316  16.8947   27.9474   37.5263 \n",
        "\n",
        "[:, :, 2] =\n",
        " 1.15202  1.15202   1.15202   1.15202\n",
        " 1.36842  1.94737   4.84211   6.73684\n",
        " 2.42105  6.15789  11.3684   14.3158 \n",
        " 4.52632  9.36842  16.6316   23.0    \n",
        "\n",
        "[:, :, 3] =\n",
        " 1.15202   1.15202  1.15202   1.15202\n",
        " 0.677728  1.42105  2.84211   3.21053\n",
        " 1.36842   4.21053  6.31579   9.21053\n",
        " 2.42105   4.68421  9.31579  14.5263 \n",
        "\n",
        "[:, :, 4] =\n",
        " 1.15202  1.15202  1.15202  1.15202\n",
        " 1.11388  1.03812  1.29212  1.94737\n",
        " 1.43902  1.63158  3.89474  4.63158\n",
        " 1.34574  4.57895  5.94737  7.68421"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Using pmap - and only one processor:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Lets add one processor:\n",
      "#addprocs(1)\n",
      "println(\"nprocs()= \",nprocs())\n",
      "println(\"nworkers()= \",nworkers())\n",
      "println(\"myid()= \",myid())\n",
      "#@everywhere using Distributions;\n",
      "#using PyPlot;\n",
      "#@everywhere const days_in_year = 365.2425;\n",
      "#Include the parallel versions:\n",
      "#@everywhere include(\"HW6_Q2_planet_populations_par.jl\")\n",
      "#PARALLEL\n",
      "srand(42)\n",
      "@time result_pmap = eval_model_on_grid_pmap(etas,shapes,scales,num_stars; num_evals = num_evals, true_eta = eta, true_shape = shape, true_scale = scale);\n",
      "#@test_approx_eq result_par2 result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "nprocs()= 1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "nworkers()= 1\n",
        "myid()= 1\n",
        "elapsed time: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3.763850759 seconds (27119564 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "64-element Array{Any,1}:\n",
        "  1.15202\n",
        "  2.10526\n",
        "  4.78947\n",
        "  7.26316\n",
        "  1.15202\n",
        "  4.78947\n",
        " 11.8947 \n",
        " 16.8947 \n",
        "  1.15202\n",
        "  7.52632\n",
        " 18.6842 \n",
        " 27.9474 \n",
        "  1.15202\n",
        "  \u22ee      \n",
        "  1.15202\n",
        "  1.03812\n",
        "  1.63158\n",
        "  4.57895\n",
        "  1.15202\n",
        "  1.29212\n",
        "  3.89474\n",
        "  5.94737\n",
        "  1.15202\n",
        "  1.94737\n",
        "  4.63158\n",
        "  7.68421"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##2e\n",
      "2e.  Compare the performance of your parallel code using map to the parallel code using @parallel.  \n",
      "Again, varry the number of processors (e.g., 1, 2, 4, 8) and make sure you use a computer that has at least 8 cores.  \n",
      "How does the wall clock time scale with the number of processors?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Comparing map, and @parallel using 2 cores:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###map"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Lets add one processor:\n",
      "#addprocs(1)\n",
      "println(\"nprocs()= \",nprocs())\n",
      "println(\"nworkers()= \",nworkers())\n",
      "println(\"myid()= \",myid())\n",
      "#@everywhere using Distributions;\n",
      "#using PyPlot;\n",
      "#@everywhere const days_in_year = 365.2425;\n",
      "#Include the parallel versions:\n",
      "#@everywhere include(\"HW6_Q2_planet_populations_par.jl\")\n",
      "#PARALLEL\n",
      "srand(42)\n",
      "@time result_pmap = eval_model_on_grid_map(etas,shapes,scales,num_stars; num_evals = num_evals, true_eta = eta, true_shape = shape, true_scale = scale);\n",
      "#@test_approx_eq result_par2 result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "nprocs()= 2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "nworkers()= 1\n",
        "myid()= 1\n",
        "elapsed time: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3.620630008 seconds (21039560 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "4x4x4 Array{Float64,3}:\n",
        "[:, :, 1] =\n",
        " 1.15202   1.15202   1.15202   1.15202\n",
        " 2.10526   4.78947   7.52632  11.7895 \n",
        " 4.78947  11.8947   18.6842   24.6316 \n",
        " 7.26316  16.8947   27.9474   37.5263 \n",
        "\n",
        "[:, :, 2] =\n",
        " 1.15202  1.15202   1.15202   1.15202\n",
        " 1.36842  1.94737   4.84211   6.73684\n",
        " 2.42105  6.15789  11.3684   14.3158 \n",
        " 4.52632  9.36842  16.6316   23.0    \n",
        "\n",
        "[:, :, 3] =\n",
        " 1.15202   1.15202  1.15202   1.15202\n",
        " 0.677728  1.42105  2.84211   3.21053\n",
        " 1.36842   4.21053  6.31579   9.21053\n",
        " 2.42105   4.68421  9.31579  14.5263 \n",
        "\n",
        "[:, :, 4] =\n",
        " 1.15202  1.15202  1.15202  1.15202\n",
        " 1.11388  1.03812  1.29212  1.94737\n",
        " 1.43902  1.63158  3.89474  4.63158\n",
        " 1.34574  4.57895  5.94737  7.68421"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###@parallel:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Lets add one processor:\n",
      "#addprocs(1)\n",
      "println(\"nprocs()= \",nprocs())\n",
      "println(\"nworkers()= \",nworkers())\n",
      "println(\"myid()= \",myid())\n",
      "#@everywhere using Distributions;\n",
      "#using PyPlot;\n",
      "#@everywhere const days_in_year = 365.2425;\n",
      "#Include the parallel versions:\n",
      "#@everywhere include(\"HW6_Q2_planet_populations_par.jl\")\n",
      "\n",
      "#PARALLEL\n",
      "srand(42)\n",
      "@time result_par2 = eval_model_on_grid_loops_par(etas,shapes,scales,num_stars; num_evals = num_evals, true_eta = eta, true_shape = shape, true_scale = scale);\n",
      "#Lets test if serial, and parallel are the same\n",
      "#@test_approx_eq result_par2 result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "nprocs()= 2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "nworkers()= 1\n",
        "myid()= 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".713674849 seconds (13269884 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "4x4x4 Array{Float64,3}:\n",
        "[:, :, 1] =\n",
        " 1.15202   1.15202   1.15202   1.15202\n",
        " 1.73684   5.89474   8.31579  11.3158 \n",
        " 5.0      11.7895   17.7895   23.1053 \n",
        " 7.05263  17.2632   25.3684   37.7895 \n",
        "\n",
        "[:, :, 2] =\n",
        " 1.15202   1.15202   1.15202   1.15202\n",
        " 1.05263   3.15789   4.10526   7.94737\n",
        " 3.10526   6.94737  11.2105   15.4737 \n",
        " 4.68421  10.8421   17.4211   26.1053 \n",
        "\n",
        "[:, :, 3] =\n",
        " 1.15202  1.15202   1.15202   1.15202\n",
        " 0.41695  1.57895   2.47368   3.21053\n",
        " 1.26316  4.10526   5.63158   8.42105\n",
        " 3.73684  6.26316  10.5789   12.9474 \n",
        "\n",
        "[:, :, 4] =\n",
        " 1.15202  1.15202   1.15202  1.15202\n",
        " 1.41929  0.736842  1.36842  2.15789\n",
        " 1.47651  1.84211   3.84211  5.15789\n",
        " 1.84211  2.78947   6.21053  6.89474"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "_We see that map is faster!_"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##2f\n",
      "2f.  Modify the code from 2e so as to make use of DistributedArrays.  When using DistributedArrays, use map, not pmap.  The function map automatically parallelizes the calculations across processors letting each processor work on the local portion of the distributed array.  map returns a distributed array with the same shape and distribution as the input DistributedArray.  (If you use pmap, then it'll take much longer, since there will be lots of unnecessary communications, and return a normal Array.)  Retest."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Lets add one processor:\n",
      "#addprocs(1)\n",
      "println(\"nprocs()= \",nprocs())\n",
      "println(\"nworkers()= \",nworkers())\n",
      "println(\"myid()= \",myid())\n",
      "@everywhere using Distributions;\n",
      "using PyPlot;\n",
      "@everywhere const days_in_year = 365.2425;\n",
      "#Include the parallel versions:\n",
      "@everywhere include(\"HW6_Q2_planet_populations_par.jl\")\n",
      "\n",
      "#PARALLEL\n",
      "srand(42)\n",
      "print(\"Map - distributed arrays: \")\n",
      "println(@elapsed result_par2 = eval_model_on_grid_map_distributed(etas,shapes,scales,num_stars; num_evals = num_evals, true_eta = eta, true_shape = shape, true_scale = scale))\n",
      "#Lets test if serial, and parallel are the same\n",
      "#@test_approx_eq result_par2 result\n",
      "\n",
      "#Lets add one processor:\n",
      "#addprocs(1)\n",
      "println(\"nprocs()= \",nprocs())\n",
      "println(\"nworkers()= \",nworkers())\n",
      "println(\"myid()= \",myid())\n",
      "#@everywhere using Distributions;\n",
      "#using PyPlot;\n",
      "#@everywhere const days_in_year = 365.2425;\n",
      "#Include the parallel versions:\n",
      "#@everywhere include(\"HW6_Q2_planet_populations_par.jl\")\n",
      "#PARALLEL\n",
      "srand(42)\n",
      "print(\"Map - standard arrays: \")\n",
      "println(@elapsed result_pmap = eval_model_on_grid_map(etas,shapes,scales,num_stars; num_evals = num_evals, true_eta = eta, true_shape = shape, true_scale = scale))\n",
      "#@test_approx_eq result_par2 result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "nprocs()= 2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "nworkers()= 1\n",
        "myid()= 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Map - distributed arrays: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "799151588\n",
        "nprocs()= 2\n",
        "nworkers()= 1\n",
        "myid()= 1\n",
        "Map - standard arrays: 3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".615035186\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##2g\n",
      "2g. Compare the performance of your parallel code using DistributedArrays to that of your code using standard arrays.  \n",
      "Explain why the performance is does not improve more signiifcantly.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see that using **distributed** arrays (and two cores), then it took 3.799 seconds, but using **standard** arrays, then it took 3.615 seconds on two cores - _they are very similar._ Now I want to try increasing num_stars:\n",
      "\n",
      "num_stars=8000"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_stars = 8000\n",
      "\n",
      "#Lets add one processor:\n",
      "#addprocs(1)\n",
      "println(\"nprocs()= \",nprocs())\n",
      "println(\"nworkers()= \",nworkers())\n",
      "println(\"myid()= \",myid())\n",
      "@everywhere using Distributions;\n",
      "using PyPlot;\n",
      "@everywhere const days_in_year = 365.2425;\n",
      "#Include the parallel versions:\n",
      "@everywhere include(\"HW6_Q2_planet_populations_par.jl\")\n",
      "\n",
      "#PARALLEL\n",
      "srand(42)\n",
      "print(\"Map - distributed arrays: \")\n",
      "println(@elapsed result_par2 = eval_model_on_grid_map_distributed(etas,shapes,scales,num_stars; num_evals = num_evals, true_eta = eta, true_shape = shape, true_scale = scale))\n",
      "#Lets test if serial, and parallel are the same\n",
      "#@test_approx_eq result_par2 result\n",
      "\n",
      "#Lets add one processor:\n",
      "#addprocs(1)\n",
      "println(\"nprocs()= \",nprocs())\n",
      "println(\"nworkers()= \",nworkers())\n",
      "println(\"myid()= \",myid())\n",
      "#@everywhere using Distributions;\n",
      "#using PyPlot;\n",
      "#@everywhere const days_in_year = 365.2425;\n",
      "#Include the parallel versions:\n",
      "#@everywhere include(\"HW6_Q2_planet_populations_par.jl\")\n",
      "#PARALLEL\n",
      "srand(42)\n",
      "print(\"Map - standard arrays: \")\n",
      "println(@elapsed result_pmap = eval_model_on_grid_map(etas,shapes,scales,num_stars; num_evals = num_evals, true_eta = eta, true_shape = shape, true_scale = scale))\n",
      "#@test_approx_eq result_par2 result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "nprocs()= 2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "nworkers()= 1\n",
        "myid()= 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Map - distributed arrays: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "17."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "756412198\n",
        "nprocs()= 2\n",
        "nworkers()= 1\n",
        "myid()= 1\n",
        "Map - standard arrays: 17"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".55775185\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see that the standard arrays are still faster - maybe the communication overhead with distributed arrays is just too much in this case? \n",
      "\n",
      "Now I want to try to use 4 cores:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_stars = 8000\n",
      "\n",
      "#Lets add two processors:\n",
      "#addprocs(2)\n",
      "println(\"nprocs()= \",nprocs())\n",
      "println(\"nworkers()= \",nworkers())\n",
      "println(\"myid()= \",myid())\n",
      "@everywhere using Distributions;\n",
      "using PyPlot;\n",
      "@everywhere const days_in_year = 365.2425;\n",
      "#Include the parallel versions:\n",
      "@everywhere include(\"HW6_Q2_planet_populations_par.jl\")\n",
      "\n",
      "#PARALLEL\n",
      "srand(42)\n",
      "print(\"Map - distributed arrays: \")\n",
      "println(@elapsed result_par2 = eval_model_on_grid_map_distributed(etas,shapes,scales,num_stars; num_evals = num_evals, true_eta = eta, true_shape = shape, true_scale = scale))\n",
      "#Lets test if serial, and parallel are the same\n",
      "#@test_approx_eq result_par2 result\n",
      "\n",
      "#Lets add one processor:\n",
      "#addprocs(1)\n",
      "println(\"nprocs()= \",nprocs())\n",
      "println(\"nworkers()= \",nworkers())\n",
      "println(\"myid()= \",myid())\n",
      "#@everywhere using Distributions;\n",
      "#using PyPlot;\n",
      "#@everywhere const days_in_year = 365.2425;\n",
      "#Include the parallel versions:\n",
      "#@everywhere include(\"HW6_Q2_planet_populations_par.jl\")\n",
      "#PARALLEL\n",
      "srand(42)\n",
      "print(\"Map - standard arrays: \")\n",
      "println(@elapsed result_pmap = eval_model_on_grid_map(etas,shapes,scales,num_stars; num_evals = num_evals, true_eta = eta, true_shape = shape, true_scale = scale))\n",
      "#@test_approx_eq result_par2 result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "nprocs()= 4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "nworkers()= 3\n",
        "myid()= 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Map - distributed arrays: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "9."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "406082059\n",
        "nprocs()= 4\n",
        "nworkers()= 3\n",
        "myid()= 1\n",
        "Map - standard arrays: 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".887696524\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Interesting; now the distributed arrays show quite the speedup; while the standard arrays are much slower."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}